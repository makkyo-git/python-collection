{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makkyo-git/python-collection/blob/mabo/infoGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qEFOrPPE68r",
        "outputId": "7ac799b1-1ecb-4599-b2fc-563021e046f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxd93fvS-1n_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "import argparse \n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNHnUefY_6nw"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"images/static/\", exist_ok=True)\n",
        "os.makedirs(\"images/varying_c1/\", exist_ok=True)\n",
        "os.makedirs(\"images/varying_c2/\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnc_7BdTe2M7"
      },
      "outputs": [],
      "source": [
        "# datasetは、自分が読み込ませたい画像のパス(ただし、階層は、直前の一つ下にすること)を書く\n",
        "dataroot = \"/content/drive/MyDrive/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da54zZkKMJD0",
        "outputId": "7b91d5c0-6180-41d0-a29a-aa50c3412c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=3, code_dim=2, f='/root/.local/share/jupyter/runtime/kernel-a11638e4-c42a-4b9b-bbde-a69be6158628.json', img_size=32, latent_dim=62, lr=0.0002, n_classes=10, n_cpu=8, n_epochs=10000, sample_interval=100)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=10000, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999,help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threada to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=62, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--code_dim\", type=int, default=2, help=\"latent code\")\n",
        "parser.add_argument(\"--n_classes\", type=int, default=10, help=\"number of classes for dataset\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval between image sampling\")\n",
        "parser.add_argument('-f')\n",
        "opt = parser.parse_args()\n",
        "print(opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlAJbpCtjYY-"
      },
      "outputs": [],
      "source": [
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                              transforms.Resize(opt.img_size),\n",
        "                              transforms.ToTensor(),\n",
        "                              # -1〜1に値域に変更\n",
        "                              transforms.Normalize([0.5], [0.5])\n",
        "                           ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkIemLhTjgVO",
        "outputId": "f38d8a76-874b-4e11-9f6f-1d6cccd8d197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wZYERfLjiBZ",
        "outputId": "b26d6d63-47db-4b8f-b20a-0523b9d19bcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1602"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLdawnAog2xu"
      },
      "outputs": [],
      "source": [
        "# データローダーを作成する\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size,shuffle=True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Z7pPggN8B_",
        "outputId": "247dafc2-0841-4a1f-b694-0bfaa63a8e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0/10000] [Batch 0/26] [D loss: 0.465714] [G loss: 0.929729] [info loss: 2.334937]\n",
            "[Epoch 0/10000] [Batch 1/26] [D loss: 0.464099] [G loss: 0.927314] [info loss: 2.338983]\n",
            "[Epoch 0/10000] [Batch 2/26] [D loss: 0.462385] [G loss: 0.923691] [info loss: 2.334156]\n",
            "[Epoch 0/10000] [Batch 3/26] [D loss: 0.460852] [G loss: 0.920677] [info loss: 2.336476]\n",
            "[Epoch 0/10000] [Batch 4/26] [D loss: 0.459255] [G loss: 0.917509] [info loss: 2.338333]\n",
            "[Epoch 0/10000] [Batch 5/26] [D loss: 0.457268] [G loss: 0.914705] [info loss: 2.336543]\n",
            "[Epoch 0/10000] [Batch 6/26] [D loss: 0.455222] [G loss: 0.910613] [info loss: 2.337285]\n",
            "[Epoch 0/10000] [Batch 7/26] [D loss: 0.453310] [G loss: 0.907095] [info loss: 2.337592]\n",
            "[Epoch 0/10000] [Batch 8/26] [D loss: 0.450425] [G loss: 0.902647] [info loss: 2.335701]\n",
            "[Epoch 0/10000] [Batch 9/26] [D loss: 0.448146] [G loss: 0.898453] [info loss: 2.337969]\n",
            "[Epoch 0/10000] [Batch 10/26] [D loss: 0.444431] [G loss: 0.893210] [info loss: 2.341158]\n",
            "[Epoch 0/10000] [Batch 11/26] [D loss: 0.440454] [G loss: 0.886436] [info loss: 2.332960]\n",
            "[Epoch 0/10000] [Batch 12/26] [D loss: 0.436021] [G loss: 0.880638] [info loss: 2.334956]\n",
            "[Epoch 0/10000] [Batch 13/26] [D loss: 0.431423] [G loss: 0.872908] [info loss: 2.336078]\n",
            "[Epoch 0/10000] [Batch 14/26] [D loss: 0.426130] [G loss: 0.862908] [info loss: 2.336641]\n",
            "[Epoch 0/10000] [Batch 15/26] [D loss: 0.416427] [G loss: 0.849546] [info loss: 2.335588]\n",
            "[Epoch 0/10000] [Batch 16/26] [D loss: 0.408532] [G loss: 0.832779] [info loss: 2.335600]\n",
            "[Epoch 0/10000] [Batch 17/26] [D loss: 0.401962] [G loss: 0.815319] [info loss: 2.331955]\n",
            "[Epoch 0/10000] [Batch 18/26] [D loss: 0.392067] [G loss: 0.783733] [info loss: 2.334756]\n",
            "[Epoch 0/10000] [Batch 19/26] [D loss: 0.377403] [G loss: 0.759876] [info loss: 2.334110]\n",
            "[Epoch 0/10000] [Batch 20/26] [D loss: 0.365663] [G loss: 0.704915] [info loss: 2.330142]\n",
            "[Epoch 0/10000] [Batch 21/26] [D loss: 0.350556] [G loss: 0.664528] [info loss: 2.336595]\n",
            "[Epoch 0/10000] [Batch 22/26] [D loss: 0.333903] [G loss: 0.606943] [info loss: 2.336330]\n",
            "[Epoch 0/10000] [Batch 23/26] [D loss: 0.310670] [G loss: 0.588373] [info loss: 2.335603]\n",
            "[Epoch 0/10000] [Batch 24/26] [D loss: 0.305197] [G loss: 0.485695] [info loss: 2.332075]\n",
            "[Epoch 0/10000] [Batch 25/26] [D loss: 0.218166] [G loss: 0.570911] [info loss: 2.354564]\n",
            "[Epoch 1/10000] [Batch 0/26] [D loss: 0.274370] [G loss: 0.423570] [info loss: 2.338437]\n",
            "[Epoch 1/10000] [Batch 1/26] [D loss: 0.258762] [G loss: 0.413174] [info loss: 2.334486]\n",
            "[Epoch 1/10000] [Batch 2/26] [D loss: 0.260096] [G loss: 0.356312] [info loss: 2.339382]\n",
            "[Epoch 1/10000] [Batch 3/26] [D loss: 0.232391] [G loss: 0.399256] [info loss: 2.334459]\n",
            "[Epoch 1/10000] [Batch 4/26] [D loss: 0.212642] [G loss: 0.376576] [info loss: 2.334090]\n",
            "[Epoch 1/10000] [Batch 5/26] [D loss: 0.192231] [G loss: 0.381067] [info loss: 2.331642]\n",
            "[Epoch 1/10000] [Batch 6/26] [D loss: 0.162973] [G loss: 0.429811] [info loss: 2.334243]\n",
            "[Epoch 1/10000] [Batch 7/26] [D loss: 0.145703] [G loss: 0.479175] [info loss: 2.333537]\n",
            "[Epoch 1/10000] [Batch 8/26] [D loss: 0.133287] [G loss: 0.471222] [info loss: 2.327013]\n",
            "[Epoch 1/10000] [Batch 9/26] [D loss: 0.100442] [G loss: 0.500444] [info loss: 2.338243]\n",
            "[Epoch 1/10000] [Batch 10/26] [D loss: 0.079414] [G loss: 0.616137] [info loss: 2.332057]\n",
            "[Epoch 1/10000] [Batch 11/26] [D loss: 0.078417] [G loss: 0.563683] [info loss: 2.329278]\n",
            "[Epoch 1/10000] [Batch 12/26] [D loss: 0.082251] [G loss: 0.615284] [info loss: 2.330351]\n",
            "[Epoch 1/10000] [Batch 13/26] [D loss: 0.083887] [G loss: 0.711743] [info loss: 2.324059]\n",
            "[Epoch 1/10000] [Batch 14/26] [D loss: 0.067216] [G loss: 0.621345] [info loss: 2.325602]\n",
            "[Epoch 1/10000] [Batch 15/26] [D loss: 0.086943] [G loss: 0.601960] [info loss: 2.319842]\n",
            "[Epoch 1/10000] [Batch 16/26] [D loss: 0.069438] [G loss: 0.650216] [info loss: 2.323561]\n",
            "[Epoch 1/10000] [Batch 17/26] [D loss: 0.076130] [G loss: 0.602514] [info loss: 2.319145]\n",
            "[Epoch 1/10000] [Batch 18/26] [D loss: 0.072075] [G loss: 0.520854] [info loss: 2.319378]\n",
            "[Epoch 1/10000] [Batch 19/26] [D loss: 0.106013] [G loss: 0.493978] [info loss: 2.315900]\n",
            "[Epoch 1/10000] [Batch 20/26] [D loss: 0.075736] [G loss: 0.645659] [info loss: 2.313575]\n",
            "[Epoch 1/10000] [Batch 21/26] [D loss: 0.071406] [G loss: 0.533965] [info loss: 2.312057]\n",
            "[Epoch 1/10000] [Batch 22/26] [D loss: 0.100948] [G loss: 0.447037] [info loss: 2.308303]\n",
            "[Epoch 1/10000] [Batch 23/26] [D loss: 0.082307] [G loss: 0.571286] [info loss: 2.299729]\n",
            "[Epoch 1/10000] [Batch 24/26] [D loss: 0.081965] [G loss: 0.592324] [info loss: 2.300165]\n",
            "[Epoch 1/10000] [Batch 25/26] [D loss: 0.012058] [G loss: 0.624850] [info loss: 2.359235]\n",
            "[Epoch 2/10000] [Batch 0/26] [D loss: 0.062133] [G loss: 0.628918] [info loss: 2.293812]\n",
            "[Epoch 2/10000] [Batch 1/26] [D loss: 0.078268] [G loss: 0.549618] [info loss: 2.293957]\n",
            "[Epoch 2/10000] [Batch 2/26] [D loss: 0.051396] [G loss: 0.634790] [info loss: 2.297143]\n",
            "[Epoch 2/10000] [Batch 3/26] [D loss: 0.053111] [G loss: 0.751016] [info loss: 2.298422]\n",
            "[Epoch 2/10000] [Batch 4/26] [D loss: 0.044919] [G loss: 0.721097] [info loss: 2.283220]\n",
            "[Epoch 2/10000] [Batch 5/26] [D loss: 0.025237] [G loss: 0.833102] [info loss: 2.281911]\n",
            "[Epoch 2/10000] [Batch 6/26] [D loss: 0.033586] [G loss: 0.890521] [info loss: 2.274994]\n",
            "[Epoch 2/10000] [Batch 7/26] [D loss: 0.036392] [G loss: 0.867578] [info loss: 2.252814]\n",
            "[Epoch 2/10000] [Batch 8/26] [D loss: 0.036247] [G loss: 0.838417] [info loss: 2.268510]\n",
            "[Epoch 2/10000] [Batch 9/26] [D loss: 0.042122] [G loss: 0.904301] [info loss: 2.235703]\n",
            "[Epoch 2/10000] [Batch 10/26] [D loss: 0.044849] [G loss: 0.902020] [info loss: 2.225840]\n",
            "[Epoch 2/10000] [Batch 11/26] [D loss: 0.040874] [G loss: 0.832537] [info loss: 2.240678]\n",
            "[Epoch 2/10000] [Batch 12/26] [D loss: 0.042225] [G loss: 0.922106] [info loss: 2.213760]\n",
            "[Epoch 2/10000] [Batch 13/26] [D loss: 0.047765] [G loss: 1.058969] [info loss: 2.195176]\n",
            "[Epoch 2/10000] [Batch 14/26] [D loss: 0.039653] [G loss: 0.816471] [info loss: 2.183702]\n",
            "[Epoch 2/10000] [Batch 15/26] [D loss: 0.044553] [G loss: 0.933207] [info loss: 2.189131]\n",
            "[Epoch 2/10000] [Batch 16/26] [D loss: 0.040550] [G loss: 0.885246] [info loss: 2.190891]\n",
            "[Epoch 2/10000] [Batch 17/26] [D loss: 0.053562] [G loss: 0.853473] [info loss: 2.134622]\n",
            "[Epoch 2/10000] [Batch 18/26] [D loss: 0.079628] [G loss: 0.866110] [info loss: 2.120575]\n",
            "[Epoch 2/10000] [Batch 19/26] [D loss: 0.049253] [G loss: 0.936204] [info loss: 2.090678]\n",
            "[Epoch 2/10000] [Batch 20/26] [D loss: 0.048924] [G loss: 0.946466] [info loss: 2.095038]\n",
            "[Epoch 2/10000] [Batch 21/26] [D loss: 0.062871] [G loss: 1.035835] [info loss: 2.070302]\n",
            "[Epoch 2/10000] [Batch 22/26] [D loss: 0.044734] [G loss: 0.949353] [info loss: 2.019537]\n",
            "[Epoch 2/10000] [Batch 23/26] [D loss: 0.061602] [G loss: 0.924630] [info loss: 2.039752]\n",
            "[Epoch 2/10000] [Batch 24/26] [D loss: 0.089462] [G loss: 0.866044] [info loss: 2.037480]\n",
            "[Epoch 2/10000] [Batch 25/26] [D loss: 0.117529] [G loss: 0.982534] [info loss: 1.927411]\n",
            "[Epoch 3/10000] [Batch 0/26] [D loss: 0.094877] [G loss: 0.894270] [info loss: 2.029435]\n",
            "[Epoch 3/10000] [Batch 1/26] [D loss: 0.066593] [G loss: 1.208449] [info loss: 2.005750]\n",
            "[Epoch 3/10000] [Batch 2/26] [D loss: 0.074101] [G loss: 1.129597] [info loss: 1.973388]\n",
            "[Epoch 3/10000] [Batch 3/26] [D loss: 0.063637] [G loss: 1.084193] [info loss: 2.053627]\n",
            "[Epoch 3/10000] [Batch 4/26] [D loss: 0.063924] [G loss: 0.892777] [info loss: 2.063315]\n",
            "[Epoch 3/10000] [Batch 5/26] [D loss: 0.063893] [G loss: 0.932775] [info loss: 1.929623]\n",
            "[Epoch 3/10000] [Batch 6/26] [D loss: 0.075768] [G loss: 0.974883] [info loss: 1.919439]\n",
            "[Epoch 3/10000] [Batch 7/26] [D loss: 0.059014] [G loss: 1.085517] [info loss: 1.878386]\n",
            "[Epoch 3/10000] [Batch 8/26] [D loss: 0.087955] [G loss: 1.018544] [info loss: 1.909394]\n",
            "[Epoch 3/10000] [Batch 9/26] [D loss: 0.060272] [G loss: 0.977829] [info loss: 1.852350]\n",
            "[Epoch 3/10000] [Batch 10/26] [D loss: 0.058097] [G loss: 0.862504] [info loss: 1.816877]\n",
            "[Epoch 3/10000] [Batch 11/26] [D loss: 0.066355] [G loss: 0.974686] [info loss: 1.840950]\n",
            "[Epoch 3/10000] [Batch 12/26] [D loss: 0.090900] [G loss: 0.994902] [info loss: 1.757752]\n",
            "[Epoch 3/10000] [Batch 13/26] [D loss: 0.068448] [G loss: 0.924107] [info loss: 1.788440]\n",
            "[Epoch 3/10000] [Batch 14/26] [D loss: 0.065791] [G loss: 0.851458] [info loss: 1.777800]\n",
            "[Epoch 3/10000] [Batch 15/26] [D loss: 0.098861] [G loss: 0.833295] [info loss: 1.781204]\n",
            "[Epoch 3/10000] [Batch 16/26] [D loss: 0.070941] [G loss: 0.822015] [info loss: 1.772718]\n",
            "[Epoch 3/10000] [Batch 17/26] [D loss: 0.079285] [G loss: 0.861174] [info loss: 1.738947]\n",
            "[Epoch 3/10000] [Batch 18/26] [D loss: 0.073822] [G loss: 0.893836] [info loss: 1.715293]\n",
            "[Epoch 3/10000] [Batch 19/26] [D loss: 0.082747] [G loss: 0.941702] [info loss: 1.736642]\n",
            "[Epoch 3/10000] [Batch 20/26] [D loss: 0.064611] [G loss: 0.919577] [info loss: 1.717701]\n",
            "[Epoch 3/10000] [Batch 21/26] [D loss: 0.065892] [G loss: 0.966018] [info loss: 1.696452]\n",
            "[Epoch 3/10000] [Batch 22/26] [D loss: 0.075950] [G loss: 1.005795] [info loss: 1.714532]\n",
            "[Epoch 3/10000] [Batch 23/26] [D loss: 0.080915] [G loss: 1.073711] [info loss: 1.754114]\n",
            "[Epoch 3/10000] [Batch 24/26] [D loss: 0.071945] [G loss: 0.964305] [info loss: 1.735229]\n",
            "[Epoch 3/10000] [Batch 25/26] [D loss: 0.071196] [G loss: 0.620236] [info loss: 1.728993]\n",
            "[Epoch 4/10000] [Batch 0/26] [D loss: 0.063165] [G loss: 1.111969] [info loss: 1.772119]\n",
            "[Epoch 4/10000] [Batch 1/26] [D loss: 0.087664] [G loss: 1.064240] [info loss: 1.843076]\n",
            "[Epoch 4/10000] [Batch 2/26] [D loss: 0.079760] [G loss: 1.011875] [info loss: 1.822768]\n",
            "[Epoch 4/10000] [Batch 3/26] [D loss: 0.091767] [G loss: 1.052723] [info loss: 1.758599]\n",
            "[Epoch 4/10000] [Batch 4/26] [D loss: 0.086230] [G loss: 0.912821] [info loss: 1.788051]\n",
            "[Epoch 4/10000] [Batch 5/26] [D loss: 0.079783] [G loss: 0.847847] [info loss: 1.753132]\n",
            "[Epoch 4/10000] [Batch 6/26] [D loss: 0.074684] [G loss: 0.794357] [info loss: 1.695539]\n",
            "[Epoch 4/10000] [Batch 7/26] [D loss: 0.084223] [G loss: 0.971645] [info loss: 1.705192]\n",
            "[Epoch 4/10000] [Batch 8/26] [D loss: 0.077446] [G loss: 0.881578] [info loss: 1.733510]\n",
            "[Epoch 4/10000] [Batch 9/26] [D loss: 0.073389] [G loss: 0.733330] [info loss: 1.680858]\n",
            "[Epoch 4/10000] [Batch 10/26] [D loss: 0.071822] [G loss: 0.925064] [info loss: 1.697393]\n",
            "[Epoch 4/10000] [Batch 11/26] [D loss: 0.070084] [G loss: 0.839624] [info loss: 1.644917]\n",
            "[Epoch 4/10000] [Batch 12/26] [D loss: 0.069318] [G loss: 0.864186] [info loss: 1.696236]\n",
            "[Epoch 4/10000] [Batch 13/26] [D loss: 0.096254] [G loss: 0.748337] [info loss: 1.725171]\n",
            "[Epoch 4/10000] [Batch 14/26] [D loss: 0.092147] [G loss: 0.784678] [info loss: 1.700893]\n",
            "[Epoch 4/10000] [Batch 15/26] [D loss: 0.090985] [G loss: 0.738831] [info loss: 1.711409]\n",
            "[Epoch 4/10000] [Batch 16/26] [D loss: 0.074374] [G loss: 0.941616] [info loss: 1.679381]\n",
            "[Epoch 4/10000] [Batch 17/26] [D loss: 0.069637] [G loss: 0.970777] [info loss: 1.714174]\n",
            "[Epoch 4/10000] [Batch 18/26] [D loss: 0.086293] [G loss: 0.924782] [info loss: 1.688733]\n",
            "[Epoch 4/10000] [Batch 19/26] [D loss: 0.073756] [G loss: 0.910375] [info loss: 1.671201]\n",
            "[Epoch 4/10000] [Batch 20/26] [D loss: 0.083367] [G loss: 0.811109] [info loss: 1.717691]\n",
            "[Epoch 4/10000] [Batch 21/26] [D loss: 0.080318] [G loss: 0.780900] [info loss: 1.690450]\n",
            "[Epoch 4/10000] [Batch 22/26] [D loss: 0.067645] [G loss: 0.930100] [info loss: 1.692935]\n",
            "[Epoch 4/10000] [Batch 23/26] [D loss: 0.087418] [G loss: 0.983469] [info loss: 1.672077]\n",
            "[Epoch 4/10000] [Batch 24/26] [D loss: 0.090795] [G loss: 0.953576] [info loss: 1.730302]\n",
            "[Epoch 4/10000] [Batch 25/26] [D loss: 0.105860] [G loss: 1.010845] [info loss: 1.612832]\n",
            "[Epoch 5/10000] [Batch 0/26] [D loss: 0.071223] [G loss: 1.007068] [info loss: 1.803389]\n",
            "[Epoch 5/10000] [Batch 1/26] [D loss: 0.104367] [G loss: 1.080683] [info loss: 1.861688]\n",
            "[Epoch 5/10000] [Batch 2/26] [D loss: 0.056546] [G loss: 0.948789] [info loss: 1.815099]\n",
            "[Epoch 5/10000] [Batch 3/26] [D loss: 0.081402] [G loss: 0.846782] [info loss: 1.778321]\n",
            "[Epoch 5/10000] [Batch 4/26] [D loss: 0.090956] [G loss: 0.758506] [info loss: 1.750925]\n",
            "[Epoch 5/10000] [Batch 5/26] [D loss: 0.088257] [G loss: 0.642010] [info loss: 1.667133]\n",
            "[Epoch 5/10000] [Batch 6/26] [D loss: 0.071059] [G loss: 0.823746] [info loss: 1.717713]\n",
            "[Epoch 5/10000] [Batch 7/26] [D loss: 0.083151] [G loss: 0.715177] [info loss: 1.760213]\n",
            "[Epoch 5/10000] [Batch 8/26] [D loss: 0.085730] [G loss: 0.741279] [info loss: 1.700817]\n",
            "[Epoch 5/10000] [Batch 9/26] [D loss: 0.080157] [G loss: 0.660460] [info loss: 1.741211]\n",
            "[Epoch 5/10000] [Batch 10/26] [D loss: 0.072729] [G loss: 0.771856] [info loss: 1.730991]\n",
            "[Epoch 5/10000] [Batch 11/26] [D loss: 0.078427] [G loss: 0.721324] [info loss: 1.680811]\n",
            "[Epoch 5/10000] [Batch 12/26] [D loss: 0.128818] [G loss: 0.918029] [info loss: 1.706528]\n",
            "[Epoch 5/10000] [Batch 13/26] [D loss: 0.075330] [G loss: 0.795580] [info loss: 1.728083]\n",
            "[Epoch 5/10000] [Batch 14/26] [D loss: 0.093405] [G loss: 0.693128] [info loss: 1.688022]\n",
            "[Epoch 5/10000] [Batch 15/26] [D loss: 0.077475] [G loss: 0.776485] [info loss: 1.737491]\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cef4a9b33485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[1;32m    229\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/漢字3種/藤/藤426.png'"
          ]
        }
      ],
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "          torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "          torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "def to_categorical(y, num_columns):\n",
        "    \"\"\"Returns one-hot encoded Variable\"\"\"\n",
        "    y_cat = np.zeros((y.shape[0], num_columns))\n",
        "    y_cat[range(y.shape[0]), y] = 1.0\n",
        "\n",
        "    return Variable(FloatTensor(y_cat))\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        input_dim = opt.latent_dim + opt.n_classes + opt.code_dim\n",
        "\n",
        "        self.init_size = opt.img_size // 4  # Initial size before upsampling\n",
        "        self.l1 = nn.Sequential(nn.Linear(input_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels, code):\n",
        "        gen_input = torch.cat((noise, labels, code), -1)\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "\n",
        "        # OutPut layers\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
        "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.n_classes), nn.Softmax())\n",
        "        self.latent_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.code_dim))\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.conv_blocks(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "        label = self.aux_layer(out)\n",
        "        latent_code = self.latent_layer(out)\n",
        "\n",
        "        return validity, label, latent_code\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "categorical_loss = torch.nn.CrossEntropyLoss()\n",
        "continuous_loss = torch.nn.MSELoss()\n",
        "\n",
        "# Loss weights\n",
        "lambda_cat = 1\n",
        "lambda_con = 0.1\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    categorical_loss.cuda()\n",
        "    continuous_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_info = torch.optim.Adam(\n",
        "    itertools.chain(generator.parameters(), discriminator.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2)    \n",
        ")\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "# Static generator inputs for sampling\n",
        "static_z = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.latent_dim))))\n",
        "static_label = to_categorical(\n",
        "    np.array([num for _ in range(opt.n_classes) for num in range(opt.n_classes)]), num_columns=opt.n_classes    \n",
        ")\n",
        "static_code = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.code_dim))))\n",
        "\n",
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits ranging from 0 ton_classes\"\"\"\n",
        "    # Static sample\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
        "    static_sample = generator(z, static_label, static_code)\n",
        "    save_image(static_sample.data, \"images/static/random_%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "\n",
        "    # Get varied c1 and c2\n",
        "    zeros = np.zeros((n_row ** 2, 1))\n",
        "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
        "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
        "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
        "    sample1 = generator(static_z, static_label, c1)\n",
        "    sample2 = generator(static_z, static_label, c2)\n",
        "    save_image(sample1.data, \"images/varying_c1/random_%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "    save_image(sample2.data, \"images/varying_c2/random_%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "\n",
        "# ----------\n",
        "# Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        labels = to_categorical(labels.numpy(), num_columns=opt.n_classes)\n",
        "\n",
        "        # ---------------\n",
        "        # Train Generator\n",
        "        # ---------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise and labels as generator input\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "        label_input = to_categorical(np.random.randint(0, opt.n_classes, batch_size), num_columns=opt.n_classes)\n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        validity, _, _ = discriminator(gen_imgs)\n",
        "        g_loss = adversarial_loss(validity, valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # -------------------\n",
        "        # Train Discriminator\n",
        "        # -------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Loss for real images\n",
        "        real_pred, _, _ = discriminator(real_imgs)\n",
        "        d_real_loss = adversarial_loss(real_pred, valid)\n",
        "\n",
        "        # Loss for fake images\n",
        "        fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
        "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        #-----------------\n",
        "        # Information Loss\n",
        "        # ----------------\n",
        "\n",
        "        optimizer_info.zero_grad()\n",
        "\n",
        "        # Sample labels\n",
        "        sampled_labels = np.random.randint(0, opt.n_classes, batch_size)\n",
        "\n",
        "        # Ground truth labels\n",
        "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n",
        "\n",
        "        # Sample noise, labela and code as generator input\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "        label_input = to_categorical(sampled_labels, num_columns=opt.n_classes)\n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
        "\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "        _, pred_label, pred_code = discriminator(gen_imgs)\n",
        "\n",
        "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + lambda_con * continuous_loss(\n",
        "            pred_code, code_input\n",
        "        )\n",
        "\n",
        "        info_loss.backward()\n",
        "        optimizer_info.step()\n",
        "\n",
        "        # ----------------\n",
        "        # Log Progress\n",
        "        # ----------------\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\"\n",
        "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), info_loss.item())\n",
        "        )\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            sample_image(n_row=10, batches_done=batches_done)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR2c4JnfV3mlwoXtjtAusS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}